summarise(
long = first(Longitude),
lat  = first(Latitude)
)
library(lubridate)
df$Date = mdy(df$Date)
df$Bird_ID = "M47698"
df$lat_col = colony$lat
df$long_col = colony$long
df$DateGMT = as.POSIXct(paste(df$Date, df$Time), format="%Y-%m-%d %H:%M:%S")
head(df)
tail(df)
df$Latitude = as.numeric(as.character(df$Latitude))
df$Longitude = as.numeric(as.character(df$Longitude))
df$lat_col = as.numeric(as.character(df$lat_col))
df$long_col = as.numeric(as.character(df$long_col))
library(geosphere)
df$bearing = bearing(df[,c("Longitude","Latitude")], df[,c("long_col","lat_col")])
df$dist_col = distGeo(df[,c("Longitude","Latitude")], df[,c("long_col","lat_col")])/1000
df$COL = ifelse( df$dist_col < 0.3, "colony", "sea" )
head(df)
write.table(df, file="M47698.txt", quote=F, row.names=F, sep="\t") # export the new data into a tab delimited *.txt
f = readLines("20292_240517.csv")
df <- read.csv2(
text   = f,
header = FALSE,
sep = ",",
quote="\"",
dec=",",
skip=7,
col.names=c("Date","Time","Latitude","Longitude","Altitude","Satellites","HDOP","PDOP","Temperature","Speed","TTFF","SNR","tbd"),
nrows = length(f),
encoding = "latin1",
stringsAsFactors = FALSE
)
require(dplyr)
colony = df %>%
summarise(
long = first(Longitude),
lat  = first(Latitude)
)
library(lubridate)
df$Date = mdy(df$Date)
df$Bird_ID = "M47959"
df$lat_col = colony$lat
df$long_col = colony$long
df$DateGMT = as.POSIXct(paste(df$Date, df$Time), format="%Y-%m-%d %H:%M:%S")
head(df)
tail(df)
df$Latitude = as.numeric(as.character(df$Latitude))
df$Longitude = as.numeric(as.character(df$Longitude))
df$lat_col = as.numeric(as.character(df$lat_col))
df$long_col = as.numeric(as.character(df$long_col))
library(geosphere)
df$bearing = bearing(df[,c("Longitude","Latitude")], df[,c("long_col","lat_col")])
df$dist_col = distGeo(df[,c("Longitude","Latitude")], df[,c("long_col","lat_col")])/1000
df$COL = ifelse( df$dist_col < 0.3, "colony", "sea" )
head(df)
write.table(df, file="M47959.txt", quote=F, row.names=F, sep="\t") # export the new data into a tab delimited *.txt
f = readLines("20301_240517.csv")
df <- read.csv2(
text   = f,
header = FALSE,
sep = ",",
quote="\"",
dec=",",
skip=7,
col.names=c("Date","Time","Latitude","Longitude","Altitude","Satellites","HDOP","PDOP","Temperature","Speed","TTFF","SNR","tbd"),
nrows = length(f),
encoding = "latin1",
stringsAsFactors = FALSE
)
require(dplyr)
colony = df %>%
summarise(
long = first(Longitude),
lat  = first(Latitude)
)
library(lubridate)
df$Date = mdy(df$Date)
df$Bird_ID = "M47697"
df$lat_col = colony$lat
df$long_col = colony$long
df$DateGMT = as.POSIXct(paste(df$Date, df$Time), format="%Y-%m-%d %H:%M:%S")
head(df)
tail(df)
df$Latitude = as.numeric(as.character(df$Latitude))
df$Longitude = as.numeric(as.character(df$Longitude))
df$lat_col = as.numeric(as.character(df$lat_col))
df$long_col = as.numeric(as.character(df$long_col))
library(geosphere)
df$bearing = bearing(df[,c("Longitude","Latitude")], df[,c("long_col","lat_col")])
df$dist_col = distGeo(df[,c("Longitude","Latitude")], df[,c("long_col","lat_col")])/1000
df$COL = ifelse( df$dist_col < 0.3, "colony", "sea" )
head(df)
write.table(df, file="M47697.txt", quote=F, row.names=F, sep="\t") # export the new data into a tab delimited *.txt
# Specify the input folder containing the CSV files and the output file path
input_folder = "/Users/vitorhpaiva/Desktop/EXP/"
output_file = "/Users/vitorhpaiva/Desktop/EXP/CB_BER_AUG24.csv"
# Function to read CSV files with semicolon separator, add a column with the file name, and export combined data
combine_csv_with_filename = function(input_folder, output_file) {
# List all CSV files in the input folder
csv_files = list.files(path = input_folder, pattern = "*.csv", full.names = TRUE)
# Initialize an empty list to store data frames
data_list = list()
# Loop through each CSV file, read it with semicolon separator, and add a column with the file name
for (csv_file in csv_files) {
# Read the CSV file with semicolon separator, fill missing columns, and disable automatic renaming
data = read.csv(csv_file, sep = ",", fill = TRUE, check.names = FALSE)
# Add a new column with the name of the file (without the directory path)
data$filename = basename(csv_file)
# Append the data to the list
data_list = append(data_list, list(data))
}
# Combine all data frames into one using bind_rows from dplyr
combined_data = bind_rows(data_list)
# Write the combined data frame to a CSV file with semicolon separator using write.table
write.table(combined_data, file = output_file, row.names = FALSE, sep = ",", col.names = TRUE, quote = FALSE)
cat("CSV files have been combined, a column with filenames has been added, and exported to", output_file, "\n")
}
# Call the function
combine_csv_with_filename(input_folder, output_file)
# Specify the input folder containing the CSV files and the output file path
input_folder = "/Users/vitorhpaiva/Desktop/EXP/"
# Specify the input folder containing the CSV files and the output file path
input_folder = "/Users/vitorhpaiva/Desktop/EXP/"
# List all .txt files in the folder
txt_files <- list.files(path = folder_path, pattern = "\\.txt$", full.names = TRUE)
# Specify the input folder containing the CSV files and the output file path
folder_path = "/Users/vitorhpaiva/Desktop/EXP/"
# List all .txt files in the folder
txt_files <- list.files(path = folder_path, pattern = "\\.txt$", full.names = TRUE)
# Initialize an empty string to store the combined content
combined_text <- ""
# Loop through each file and concatenate its content
for (file in txt_files) {
# Read the content of the file
file_content <- readLines(file, warn = FALSE)
# Combine the file content with the previous content
combined_text <- paste(combined_text, paste(file_content, collapse = "\n"), sep = "\n")
}
# Write the combined content to a new file
output_file = "/Users/vitorhpaiva/Desktop/EXP/CB_BER_AUG24.csv"
writeLines(combined_text, output_file)
cat("All files have been combined into", output_file)
# Specify the input folder containing the CSV files and the output file path
folder_path = "/Users/vitorhpaiva/Desktop/EXP/"
# List all .txt files in the folder
txt_files <- list.files(path = folder_path, pattern = "\\.txt$", full.names = TRUE)
# Initialize an empty string to store the combined content
combined_text <- ""
# Loop through each file and concatenate its content
for (file in txt_files) {
# Read the content of the file
file_content <- readLines(file, warn = FALSE)
# Combine the file content with the previous content
combined_text <- paste(combined_text, paste(file_content, collapse = "\n"), sep = "\n")
}
# Write the combined content to a new file
output_file = "/Users/vitorhpaiva/Desktop/EXP/CB_BER_AUG24.csv"
write.csv(combined_data, file = output_file, row.names = FALSE)
cat("All files have been combined into", output_file)
# Specify the input folder containing the CSV files and the output file path
folder_path = "/Users/vitorhpaiva/Desktop/EXP/"
# List all .txt files in the folder
txt_files <- list.files(path = folder_path, pattern = "\\.txt$", full.names = TRUE)
# Initialize an empty data frame to store the combined content
combined_data <- data.frame()
# Loop through each file and read its tab-delimited content into a data frame
for (file in txt_files) {
# Read the file content as tab-delimited
file_content <- read.table(file, header = TRUE, sep = "\t", stringsAsFactors = FALSE)
# Combine the data frames row-wise
combined_data <- rbind(combined_data, file_content)
}
# Write the combined content to a CSV file
output_file <- "/Users/vitorhpaiva/Desktop/EXP/CB_BER_AUG24.csv"
write.csv(combined_data, file = output_file, row.names = FALSE)
# Specify the input folder containing the CSV files and the output file path
folder_path = "/Users/vitorhpaiva/Desktop/EXP/"
# List all .txt files in the folder
txt_files <- list.files(path = folder_path, pattern = "\\.txt$", full.names = TRUE)
# Initialize an empty data frame to store the combined content
combined_data <- data.frame()
# Loop through each file and read its tab-delimited content into a data frame
for (file in txt_files) {
# Read the file content as tab-delimited
file_content <- read.table(file, header = TRUE, sep = "\t", stringsAsFactors = FALSE)
# Combine the data frames row-wise
combined_data <- rbind(combined_data, file_content)
}
# Write the combined content to a CSV file
output_file <- "/Users/vitorhpaiva/Desktop/EXP/CB_BER_MAY24.csv"
write.csv(combined_data, file = output_file, row.names = FALSE)
cat("All files have been combined and exported as", output_file)
# Specify the input folder containing the CSV files and the output file path
folder_path = "/Users/vitorhpaiva/Desktop/EXP/"
# List all .txt files in the folder
txt_files <- list.files(path = folder_path, pattern = "\\.txt$", full.names = TRUE)
# Initialize an empty data frame to store the combined content
combined_data <- data.frame()
# Loop through each file and read its tab-delimited content into a data frame
for (file in txt_files) {
# Read the file content as tab-delimited
file_content <- read.table(file, header = TRUE, sep = "\t", stringsAsFactors = FALSE)
# Combine the data frames row-wise
combined_data <- rbind(combined_data, file_content)
}
# Write the combined content to a CSV file
output_file <- "/Users/vitorhpaiva/Desktop/EXP/IA_DES_MAY24.csv"
write.csv(combined_data, file = output_file, row.names = FALSE)
# Specify the input folder containing the CSV files and the output file path
folder_path = "/Users/vitorhpaiva/Desktop/EXP/"
# List all .txt files in the folder
txt_files <- list.files(path = folder_path, pattern = "\\.txt$", full.names = TRUE)
# Initialize an empty data frame to store the combined content
combined_data <- data.frame()
# Loop through each file and read its tab-delimited content into a data frame
for (file in txt_files) {
# Read the file content as tab-delimited
file_content <- read.table(file, header = TRUE, sep = "\t", stringsAsFactors = FALSE)
# Combine the data frames row-wise
combined_data <- rbind(combined_data, file_content)
}
# Write the combined content to a CSV file
output_file <- "/Users/vitorhpaiva/Desktop/EXP/LM_DES_MAY24.csv"
write.csv(combined_data, file = output_file, row.names = FALSE)
# Specify the input folder containing the CSV files and the output file path
folder_path = "/Users/vitorhpaiva/Desktop/EXP/"
# List all .txt files in the folder
txt_files <- list.files(path = folder_path, pattern = "\\.txt$", full.names = TRUE)
# Initialize an empty data frame to store the combined content
combined_data <- data.frame()
# Loop through each file and read its tab-delimited content into a data frame
for (file in txt_files) {
# Read the file content as tab-delimited
file_content <- read.table(file, header = TRUE, sep = "\t", stringsAsFactors = FALSE)
# Combine the data frames row-wise
combined_data <- rbind(combined_data, file_content)
}
# Write the combined content to a CSV file
output_file <- "/Users/vitorhpaiva/Desktop/EXP/LM_BER_MAY24.csv"
write.csv(combined_data, file = output_file, row.names = FALSE)
cat("All files have been combined and exported as", output_file)
# Install and load necessary libraries
if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")
if (!requireNamespace("openxlsx", quietly = TRUE)) install.packages("openxlsx")
if (!requireNamespace("nlme", quietly = TRUE)) install.packages("nlme")
library(mgcv)
library(dplyr)
library(openxlsx)
library(nlme)
# Prompt user to select the dataset file
data_file_path <- file.choose()
cat("Selected dataset file:", data_file_path, "\n")
# Load and prepare the dataset
data <- read.csv(data_file_path)
cat("Data loaded successfully.\n")
data <- data %>%
mutate(across(c(id, cell, cond, layer), as.factor),
radius = as.numeric(radius),
intersections = log(intersections + 1))
# Prompt user to select the dataset file
data_file_path <- file.choose()
cat("Selected dataset file:", data_file_path, "\n")
# Load and prepare the dataset
data <- read.csv(data_file_path)
cat("Data loaded successfully.\n")
data <- data %>%
mutate(across(c(id, cell, cond, layer), as.factor),
radius = as.numeric(radius),
intersections = log(intersections + 1))
# Find the maximum radius value
max_radius <- max(data$radius, na.rm = TRUE)
# Define and ensure the Results directory exists
results_dir <- "Results"
if (!dir.exists(results_dir)) dir.create(results_dir)
cat("Results directory checked/created.\n")
# Define control parameters
control_params <- lmeControl(opt = "optim", msMaxIter = 500, msVerbose = FALSE)
# Parameters description
parameters_description <- data.frame(
Parameter = c("Model Formula", "Random Effect Structure", "Correlation Structure", "Data", "Control Parameters"),
Description = c(
"intersections ~ cond * radius",
"~ 1 | id/cell",
"corAR1(form = ~ radius | id/cell)",
paste("Data loaded from", basename(data_file_path)),
"lmeControl(opt = 'optim', msMaxIter = 500, msVerbose = TRUE)"
)
)
# Initialize lists to store results
results_by_radius <- list()
results_by_layer <- list()
original_model_summaries <- list()
# Fit the model by radius for the entire dataset
for (radius in 1:max_radius) {
data_radius <- filter(data, radius == !!radius)
fit_radius_model <- function() {
tryCatch({
lme(intersections ~ cond,
random = ~ 1 | id,
data = data_radius,
control = control_params)
}, error = function(e) {
NULL
})
}
radius_model <- fit_radius_model()
if (is.null(radius_model)) next
radius_coefficients_df <- as.data.frame(summary(radius_model)$tTable)
radius_coefficients_df$Term <- rownames(radius_coefficients_df)
radius_coefficients_df$Radius <- radius
radius_coefficients_df <- subset(radius_coefficients_df, grepl("condIL-4", Term))
if (nrow(radius_coefficients_df) > 0) {
results_by_radius[[as.character(radius)]] <- radius_coefficients_df
}
}
# Combine all radius-specific results and apply multiple comparison corrections
combined_radius_results_df <- bind_rows(results_by_radius) %>%
mutate(
Adjusted_P_Holm = p.adjust(`p-value`, method = "holm"),
Adjusted_P_Sidak = 1 - (1 - `p-value`) ^ length(`p-value`)
)
cat("Fitting original model\n")
fit_original_model <- function() {
tryCatch({
gamm(intersections ~ cond + s(radius, by = cond, bs = "tp") ,  # Include spline for radius
random = list(cell = ~ 1 | id/cell),  # Random intercept for cell within id
correlation = corAR1(form = ~ radius | id/cell), # Autoregressive correlation
data = data,
family = quasipoisson(link = "identity"))
}, error = function(e) {
print(e)
})
}
original_model <- fit_original_model()
if (!is.null(original_model)) {
summary_table <- summary(original_model$gam)$p.table
original_model_coefficients_df <- as.data.frame(summary_table)
original_model_coefficients_df$Term <- rownames(original_model_coefficients_df)
original_model_coefficients_df <- subset(original_model_coefficients_df, grepl("condIL-4", Term))
} else {
original_model_coefficients_df <- data.frame()
}
print(original_model_coefficients_df)
# Separate data by layer and perform analysis
for (layer in unique(data$layer)) {
data_layer <- filter(data, layer == !!layer)
layer_radius_results <- list()
for (radius in 1:max_radius) {
data_radius <- filter(data_layer, radius == !!radius)
fit_radius_model <- function() {
tryCatch({
lme(intersections ~ cond,
random = ~ 1 | id,
data = data_radius,
control = control_params)
}, error = function(e) {
NULL
})
}
radius_model <- fit_radius_model()
if (is.null(radius_model)) next
radius_coefficients_df <- as.data.frame(summary(radius_model)$tTable)
radius_coefficients_df$Term <- rownames(radius_coefficients_df)
radius_coefficients_df$Radius <- radius
radius_coefficients_df$Layer <- layer
radius_coefficients_df <- subset(radius_coefficients_df, grepl("condIL-4", Term))
if (nrow(radius_coefficients_df) > 0) {
layer_radius_results[[as.character(radius)]] <- radius_coefficients_df
}
}
if (length(layer_radius_results) > 0) {
combined_layer_results_df <- bind_rows(layer_radius_results) %>%
mutate(
Adjusted_P_Holm = p.adjust(`p-value`, method = "holm"),
Adjusted_P_Sidak = 1 - (1 - `p-value`) ^ length(`p-value`)
)
results_by_layer[[as.character(layer)]] <- combined_layer_results_df
fit_layer_model <- function() {
tryCatch({
gamm(intersections ~ cond + s(radius, by = cond, bs = "tp") ,  # Include spline for radius
random = list(cell = ~ 1 | id/cell),  # Random intercept for cell within id
correlation = corAR1(form = ~ radius | id/cell), # Gaussian correlation
data = data_layer,
family = quasipoisson(link = "identity"))
}, error = function(e) {
print(e)
})
}
layer_model <- fit_layer_model()
if (!is.null(layer_model)) {
summary_table <- summary(layer_model$gam)$p.table
layer_model_coefficients_df <- as.data.frame(summary_table)
layer_model_coefficients_df$Term <- rownames(layer_model_coefficients_df)
layer_model_coefficients_df$Layer <- layer
layer_model_coefficients_df <- subset(layer_model_coefficients_df, grepl("condIL-4", Term))
if (nrow(layer_model_coefficients_df) > 0) {
original_model_summaries[[as.character(layer)]] <- layer_model_coefficients_df
}
}
}
}
# Create a workbook to save results
wb <- createWorkbook()
# Add sheets to the workbook
addWorksheet(wb, "Mixed_Model")
writeDataTable(wb, "Mixed_Model", original_model_coefficients_df)
addWorksheet(wb, "Radius_Specific_Summary")
writeDataTable(wb, "Radius_Specific_Summary", combined_radius_results_df)
for (layer in unique(data$layer)) {
addWorksheet(wb, paste0("Layer_", layer, "_Summary"))
writeDataTable(wb, paste0("Layer_", layer, "_Summary"), results_by_layer[[as.character(layer)]])
addWorksheet(wb, paste0("Mixed_Model_Layer_", layer))
writeDataTable(wb, paste0("Mixed_Model_Layer_", layer), original_model_summaries[[as.character(layer)]])
}
addWorksheet(wb, "Parameters_Description")
writeData(wb, "Parameters_Description", parameters_description, headerStyle = createStyle(textDecoration = "bold"))
# Save the workbook
combined_summary_file_name <- paste0("Mixed_Model_", gsub(".csv", "", basename(data_file_path)), ".xlsx")
saveWorkbook(wb, file = file.path(results_dir, combined_summary_file_name), overwrite = TRUE)
cat("Combined summary coefficients, original model results, and parameters saved to", combined_summary_file_name, "\n")
# Step 1: Load your tracking data
pdeserta = read.table("pd_all.txt", h=T, sep="\t") # import
setwd("~/Documents/Documents – MacBook Pro Vitor Paiva/DESKTOP/LECTURES/UCA_AnimMove_Workshop/S1_Practice")
# Step 1: Load your tracking data
pdeserta = read.table("pd_all.txt", h=T, sep="\t") # import
head(pdeserta)   # check the structure of the object
names(pdeserta)
# Load necessary library
library(dplyr)
set.seed(123)  # Set a seed for reproducibility
# Step 1: Randomly select 5 unique BIRD_IDs
selected_bird_ids <- pdeserta %>%
distinct(BIRD_ID) %>%
sample_n(5)
# Step 2: Filter the original data frame for the selected BIRD_IDs
pdeserta_5 <- pdeserta %>%
filter(BIRD_ID %in% selected_bird_ids$BIRD_ID)
# View the sampled data
print(pdeserta_5)
unique(pdeserta_5$BIRD_ID)
head(pdeserta_5)
move_data = pdeserta_5
# Step 2: Inspect the data structure
print("Inspecting the structure of the tracking data:")
str(move_data)  # Check structure of the data frame
print("First few rows of the tracking data:")
# Step 1: Randomly select 5 unique BIRD_IDs
selected_bird_ids <- pdeserta %>%
distinct(BIRD_ID) %>%
sample_n(5)
# Step 2: Filter the original data frame for the selected BIRD_IDs
pdeserta_5 <- pdeserta %>%
filter(BIRD_ID %in% selected_bird_ids$BIRD_ID)
# View the sampled data
print(pdeserta_5)
unique(pdeserta_5$BIRD_ID)
head(pdeserta_5)
move_data = pdeserta_5
# Step 2: Inspect the data structure
print("Inspecting the structure of the tracking data:")
str(move_data)  # Check structure of the data frame
print("First few rows of the tracking data:")
head(move_data)  # Preview the first few rows of move_data
# Step 3: Ensure timestamp is in POSIXct format
move_data$timestamp <- as.POSIXct(move_data$timestamp)
str(move_data)
# Step 4: Sort the data by timestamp to ensure ascending order
move_data <- move_data[order(move_data$timestamp), ]
# Step 5: Remove duplicate timestamps
move_data <- move_data[!duplicated(move_data$timestamp), ]
names(move_data)
#Use Movevis to  make the animaion
#convert the data to a move object
require(moveVis)
move_object <-
df2move(
move_data,
proj = "+proj=longlat +datum=WGS84",
x = "LON",
y = "LAT",
time = "timestamp",
track_id = "BIRD_ID"
)
# Step 7: Align the movement data to a uniform time scale
move_data_aligned <- align_move(move_object, res = 10, unit = "hours")
# Generate 17 distinct colors using a color space palette
library(colorspace)
colors_5 <- qualitative_hcl(5, palette = "Dark 3")  # Change palette for different styles
# Step 7: Define colors based on the number of unique tracks
# Ensure there are enough colors for the number of tracks
colors <- c("red", "blue", "green", "violet", "orange") # Add more colors if needed
# Check all background maps available
get_maptypes()
# Step 8: Animate the movement tracks with specified path colors
# Run the function and capture any error message
frames <- frames_spatial(move_data_aligned,
map_service = "esri", map_type = "world_topo_map")
# Step 9: Customize the frames
frames <- add_labels(frames, x = "Longitude", y = "Latitude", title = "Animal Movement with Specified Colors")
frames <- add_northarrow(frames)
frames <- add_progress(frames) # add a progress bar
frames <- add_scalebar(frames, dist = 500, height = 0.02)
# Add timestamps directly to the frames (no need to pass 'move_data_aligned')
frames <- add_timestamps(frames, size = 4, colour = "black", type="label")
frames[[20]] # preview one of the frames, e.g. the 20th frame
# Step 10: Animate the frames and save the animation as a GIF
animate_frames(frames, fps = 20, out_file = "animate_pdeserta.gif",overwrite = T)
str(pdeserta)                                               # check the structure of the object
plot(LAT~LON, data=pdeserta)
